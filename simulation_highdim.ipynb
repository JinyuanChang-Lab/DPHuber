{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c960440",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "This cell imports the necessary Python libraries for the analysis. It includes the custom `functions_main` library, `numpy` and `numpy.random` for numerical calculations, `matplotlib.pyplot` for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d27b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"   # mac/Accelerate  \n",
    "from functions_main import *   \n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import numpy.random as rgt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from matplotlib.ticker import MaxNLocator \n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm  \n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a69021",
   "metadata": {},
   "source": [
    "# Model for High-Dimensional Data \n",
    "We simulate high-dimensional data based on the model:\n",
    "\n",
    "\n",
    "Y =  X β +  ε  \n",
    "\n",
    "\n",
    "where X ~ N(0, Sigma) with Sigma_{ij} = 0.1^{|i-j|}; the first s^* elements of β are set to either 1 or -1, and the remaining elements are zero. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da214c0",
   "metadata": {},
   "source": [
    "##   Inputs required\n",
    "\n",
    "n/p: sample size/dimension  \n",
    "\n",
    "Gaussian_error: (1)True, ε ~ N(0,1);   (2)False,   ε ~ t_{2.25} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c0f0bf",
   "metadata": {},
   "source": [
    "## Functions for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4123ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### 1. DP support recovery ########################\n",
    "def dp_top_s_laplace_peeling(u , s , eps , Delta , keep_order  = True, rng=None): \n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    p = u.shape[0]\n",
    "    s = int(min(max(s, 0), p))\n",
    "    if s == 0: return np.array([], dtype=int)\n",
    "    eps_each = eps / s\n",
    "    scale    = Delta / eps_each   # = (s * Delta) / eps\n",
    "    chosen = []\n",
    "    mask   = np.ones(p, dtype=bool)\n",
    "    for _ in range(s):\n",
    "        noise = rng.laplace(0.0, scale, size=p)\n",
    "        scores = np.where(mask, u + noise, -np.inf)\n",
    "        j = int(np.argmax(scores))\n",
    "        chosen.append(j)\n",
    "        mask[j] = False\n",
    "    idx = np.array(chosen, dtype=int)\n",
    "    if keep_order:\n",
    "        idx.sort()                \n",
    "    return idx\n",
    "\n",
    "####################### 2. DP estimation of standard deviation ########################\n",
    "def St_DP(Y, epsilon):\n",
    "\n",
    "    \"\"\"\n",
    "    (ε,0)-DP estimator of the standard deviation based on clipping and the Laplace mechanism.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y : n by 1 numpy array of response variables. \n",
    "    epsilon :  privacy parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    n =  Y.size\n",
    "    gamma = np.log(n)\n",
    "    y =  np.clip(np.asarray(Y, dtype=float), -gamma, gamma)\n",
    "    m1 = y.mean()\n",
    "    m2 = np.mean(y**2)  \n",
    "    Delta1 = 2*gamma / n\n",
    "    Delta2 = (gamma**2) / n\n",
    "\n",
    "    epsilon1 = epsilon2 = epsilon /2    # Split the privacy budget equally between the mean and second moment\n",
    "    b1 = Delta1 / float(epsilon1)\n",
    "    b2 = Delta2 / float(epsilon2)\n",
    "    noise1 =  rgt.laplace(0.0, b1)\n",
    "    noise2 =  rgt.laplace(0.0, b2) \n",
    "         \n",
    "    m1_dp = m1 + noise1\n",
    "    m2_dp = m2 + noise2\n",
    "    var_dp = float(m2_dp - m1_dp**2)\n",
    "    if var_dp > 0:\n",
    "        st_dp = np.sqrt(var_dp)\n",
    "    else:\n",
    "        st_dp = 2.0\n",
    "    return st_dp\n",
    "\n",
    "#####################  3. huber & ridge initialization #####################  \n",
    "def huber_ridge_priv(X, Y, tau, epsilon, delta): \n",
    "\n",
    "    '''\n",
    "    Huber + ridge regression & output perturbation\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    X : n by p0 numpy array of covariates; each row is an observation vector. (no intercept)\n",
    "    Y : n by 1 numpy array of response variables. \n",
    "    tau : (DP) robust parameter for huber regression.\n",
    "    epsilon,delta : privacy parameters.   \n",
    "    '''\n",
    "\n",
    "    n, p0 = X.shape\n",
    "    gamma = np.sqrt(p0+1)/6 \n",
    "    X_t = clipping_l2(X, gamma) \n",
    " \n",
    "    Z = np.hstack([np.ones((n, 1)), X_t])   # [1, X̃]\n",
    "    beta = cp.Variable(p0 + 1) \n",
    "\n",
    "    resid = Y - Z  @ beta\n",
    "    lam = 0.2 # Ridge regularization parameter\n",
    "    obj = (1.0 / n) * cp.sum(cp.huber(resid, tau)) + 0.5 * lam * cp.sum_squares(  beta) \n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(obj)) \n",
    "    prob.solve(solver=\"SCS\", verbose=False, warm_start=True)\n",
    "\n",
    "    b = np.asarray(beta.value).ravel() \n",
    "    B = np.sqrt(1 + gamma**2)\n",
    "    noise_scale = 2*B*tau*((  ( 2 *np.log(1.25 /delta))**0.5 ))/(n*epsilon*lam)\n",
    "    bDP = b + noise_scale * rgt.standard_normal(p0 + 1)\n",
    "    return bDP  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1c727",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_priv_est(n,p,Gaussian_error=True):\n",
    "    # true beta\n",
    "    rgt.seed(0) # set seed\n",
    "    beta = np.zeros(p)  # initial beta  \n",
    "    s_star = 10\n",
    "    beta[:s_star] =  np.ones(s_star)*(2*rgt.binomial(1, 0.5, size=s_star)-1)  \n",
    "    beta_norm = beta.dot(beta)**0.5 \n",
    "    beta_slope = beta[1:]\n",
    "    beta_slope_norm = beta_slope.dot(beta_slope)**0.5 \n",
    "    \n",
    "    #privacy parameters \n",
    "    epsilon = np.array([0.5,0.9 ])\n",
    "    delta  = 10/(n**1.1)\n",
    "    eps_s = epsilon/3\n",
    "    eps_init = epsilon/3\n",
    "    eps_main = epsilon/3  \n",
    "    delta_init = delta/2\n",
    "    delta_main = delta/2   \n",
    "    \n",
    "    repetitions = 300 # number of repetitions    \n",
    "    rela_l2 = np.zeros([  repetitions])  # relative l2-error results of the non-private estimate \n",
    "    priv_rela_l2_1 = np.zeros([  repetitions]) # relative l2-error results of the private estimate under epsilon = 0.5\n",
    "    priv_rela_l2_2  = np.zeros([  repetitions]) # relative l2-error results of the private estimate under epsilon = 0.9\n",
    "    rela_l2_comp = np.zeros([  repetitions])  # for slope estimation comparison\n",
    "    priv_rela_l2_comp = np.zeros([  repetitions])  # for slope estimation comparison \n",
    "    for m in range(repetitions):\n",
    "        rgt.seed(m+10) # set seed\n",
    "        \n",
    "        ############# generate data ################ \n",
    "        # X \n",
    "        idx = np.arange(p-1)\n",
    "        Sigma = 0.1 ** np.abs(idx[:, None] - idx[None, :])\n",
    "        L = np.linalg.cholesky(Sigma)  # Sigma = L @ L.T  (L lower-triangular)\n",
    "        Z = rgt.normal(size=(n, p-1))  # iid N(0,1)\n",
    "        X = Z @ L.T                        # each row has Cov = Sigma\n",
    "        # error\n",
    "        if Gaussian_error: err = rgt.normal(0,1, n)\n",
    "        else: err = rgt.standard_t(2.25, n) \n",
    "        # Y\n",
    "        Y = beta[0] + X.dot(beta[1:]) +  err\n",
    "        \n",
    "\n",
    "        ############################################### \n",
    "        #-------------  Private (proposed)  ----------- \n",
    "        ############################################### \n",
    "\n",
    "        #----------- index selection ----------- \n",
    "        xi = np.sqrt(np.log(n)+np.log(p))  \n",
    "        U = X * Y[:, None]\n",
    "        absU = np.abs(U)\n",
    "        weights = np.where(absU > 0.0, np.minimum(xi / absU, 1.0), 1.0)\n",
    "        U_tilde = U * weights\n",
    "        g = np.abs(U_tilde.mean(axis=0)) \n",
    "        # Global replace-one sensitivity for each score: Δ = 2C / n\n",
    "        Delta = 2.0 * xi / n\n",
    "        s = int(np.ceil(1.2 * s_star))\n",
    "        dx_peel_1 = dp_top_s_laplace_peeling(g, s-1, eps_s[0], Delta, rng=rgt)\n",
    "        dx_peel_2 = dp_top_s_laplace_peeling(g, s-1, eps_s[1], Delta, rng=rgt)\n",
    "\n",
    "        #----------- initialization -----------\n",
    "        support_org_1 = np.asarray(list(dx_peel_1), dtype=int)\n",
    "        support_org_2 = np.asarray(list(dx_peel_2), dtype=int)\n",
    "        X_low_1 = X[:,support_org_1]\n",
    "        X_low_2 = X[:,support_org_2]\n",
    "        epsilon_tau =  eps_init/4  # privacy budget for DP standard deviation estimation: 1/4\n",
    "        epsilon_ridge =  3*eps_init/4 # privacy budget for DP huber+ridge estimation: 3/4\n",
    "        tau_init_1 =   St_DP(Y, epsilon = epsilon_tau[0]) \n",
    "        tau_init_2 =   St_DP(Y, epsilon = epsilon_tau[1])   \n",
    "        beta_0DP_1 =  huber_ridge_priv(X_low_1, Y, tau=tau_init_1, epsilon= epsilon_ridge[0], delta= delta_init) \n",
    "        beta_0DP_2 =  huber_ridge_priv(X_low_2, Y, tau=tau_init_2, epsilon= epsilon_ridge[1], delta= delta_init)\n",
    "        beta0DP_1 = np.zeros(p)\n",
    "        support_selected_1 = np.insert(support_org_1 + 1, 0, 0).astype(int) \n",
    "        beta0DP_1[support_selected_1] = beta_0DP_1 \n",
    "        beta0DP_2 = np.zeros(p)\n",
    "        support_selected_2 = np.insert(support_org_2 + 1, 0, 0).astype(int) \n",
    "        beta0DP_2[support_selected_2] = beta_0DP_2 \n",
    "        \n",
    "        #----------- estimation -----------\n",
    "        tau_priv_1 = .04 * tau_init_1 * (n*epsilon[0]/(s*np.log(p)+np.log(n)))**0.5 # robustification parameter for  DP    \n",
    "        tau_priv_2 = .04 * tau_init_2 * (n*epsilon[1]/(s*np.log(p)+np.log(n)))**0.5  \n",
    "        lr_priv =  0.01  \n",
    "        B_priv = 0.5*(np.log(p) + np.log(n))**0.5\n",
    "        T_priv = int(np.ceil(2*np.log(n))) # number of iterations\n",
    "        if T_priv*np.log(T_priv/delta_main) < 2.5*np.log(2/delta_main)*np.log((2*T_priv)/delta_main):\n",
    "            epsilon_scale_priv = eps_main/T_priv\n",
    "            delta_scale_priv = delta_main/T_priv\n",
    "        else: \n",
    "            epsilon_scale_priv = eps_main/np.sqrt(2.5*T_priv*np.log(2/delta_main))\n",
    "            delta_scale_priv = delta_main/ (2*T_priv)\n",
    "        model_est = Huber(X , Y ,intercept=True)\n",
    "        out_priv_1 = model_est.noisygd_highdim( s=s, lr=lr_priv, T=T_priv,  tau=tau_priv_1 , beta0=beta0DP_1,  B_high=B_priv,  epsilon_scale =epsilon_scale_priv[0],  delta_scale=delta_scale_priv )    \n",
    "        priv_rela_l2_1[m]  = np.log((np.sum((out_priv_1['beta']  - beta )**2 ))**0.5  / beta_norm )\n",
    "        priv_rela_l2_comp[m] = np.log((np.sum((out_priv_1['beta'][1:]  - beta_slope )**2 ))**0.5  / beta_slope_norm ) # epsilon = 0.5 for comparison with DP-ls\n",
    "        out_priv_2 = model_est.noisygd_highdim( s=s, lr=lr_priv, T=T_priv,  tau=tau_priv_2 , beta0=beta0DP_2,  B_high=B_priv,  epsilon_scale =epsilon_scale_priv[1],  delta_scale=delta_scale_priv )    \n",
    "        priv_rela_l2_2[m]  = np.log((np.sum((out_priv_2['beta']  - beta )**2 ))**0.5  / beta_norm )\n",
    "            \n",
    "        \n",
    "        ############################################### \n",
    "        #----------------  Non-private  --------------- \n",
    "        # ###############################################  \n",
    "\n",
    "        tau0 = np.sqrt(np.mean(Y**2)-(np.mean(Y)**2))\n",
    "        tau_np_high = .1 *tau0  * (n/(s*np.log(p)+np.log(n)))**0.5  # robustification parameter for noiseless Gaussian DP \n",
    "        lr_np =  0.2  \n",
    "        T_np = int(np.ceil(2*np.log(n))) # number of iterations \n",
    "        model_est = Huber(X , Y ,intercept=True)\n",
    "        out_np = model_est.gd_highdim(s=s, lr=lr_np, T=T_np,  tau=tau_np_high, beta0=np.array([]),  standardize= False) \n",
    "        rela_l2[m]  =  np.log((np.sum((out_np['beta']   - beta  )**2))**0.5  / beta_norm)\n",
    "        rela_l2_comp[m] = np.log((np.sum((out_np['beta'][1:]  - beta_slope )**2 ))**0.5  / beta_slope_norm ) # for comparison with DP-ls\n",
    "\n",
    " \n",
    "            \n",
    "    return np.array([priv_rela_l2_1,priv_rela_l2_2,rela_l2,priv_rela_l2_comp,rela_l2_comp ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "re_high_test = main_priv_est(5000,5000,Gaussian_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6791da7",
   "metadata": {},
   "source": [
    "## Main function  adapted for parallel computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3cb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_priv_est_parallel(m): \n",
    "    n_set = np.array([5000,10000,15000  ])\n",
    "    p_set = np.array([5000 , 10000      ])  \n",
    "    TF_set = np.array([True ,False])\n",
    "    results = []\n",
    "    for p in p_set: \n",
    "        for Gaussian_error in TF_set: \n",
    "            for n in n_set:\n",
    "                # true beta\n",
    "                rgt.seed(0) # set seed\n",
    "                beta = np.zeros(p)  # initial beta  \n",
    "                s_star = 10\n",
    "                beta[:s_star] =  np.ones(s_star)*(2*rgt.binomial(1, 0.5, size=s_star)-1)  \n",
    "                beta_norm = beta.dot(beta)**0.5 \n",
    "                beta_slope = beta[1:]\n",
    "                beta_slope_norm = beta_slope.dot(beta_slope)**0.5 \n",
    "                \n",
    "                #privacy parameters \n",
    "                epsilon = np.array([0.5,0.9 ])\n",
    "                delta  = 10/(n**1.1)\n",
    "                eps_s = epsilon/3\n",
    "                eps_init = epsilon/3\n",
    "                eps_main = epsilon/3  \n",
    "                delta_init = delta/2\n",
    "                delta_main = delta/2  \n",
    "\n",
    "                rgt.seed(m+10) # set seed\n",
    "                \n",
    "                ############# generate data ################ \n",
    "                # X \n",
    "                idx = np.arange(p-1)\n",
    "                Sigma = 0.1 ** np.abs(idx[:, None] - idx[None, :])\n",
    "                L = np.linalg.cholesky(Sigma)  # Sigma = L @ L.T  (L lower-triangular)\n",
    "                Z = rgt.normal(size=(n, p-1))  # iid N(0,1)\n",
    "                X = Z @ L.T                        # each row has Cov = Sigma\n",
    "                # error\n",
    "                if Gaussian_error: err = rgt.normal(0,1, n)\n",
    "                else: err = rgt.standard_t(2.25, n) \n",
    "                # Y\n",
    "                Y = beta[0] + X.dot(beta[1:]) +  err\n",
    "                \n",
    "\n",
    "                ############################################### \n",
    "                #-------------  Private (proposed)  ----------- \n",
    "                ############################################### \n",
    "\n",
    "                #----------- index selection -----------\n",
    "                xi = np.sqrt(np.log(n)+np.log(p))  \n",
    "                U = X * Y[:, None]\n",
    "                absU = np.abs(U)\n",
    "                weights = np.where(absU > 0.0, np.minimum(xi / absU, 1.0), 1.0)\n",
    "                U_tilde = U * weights\n",
    "                g = np.abs(U_tilde.mean(axis=0)) \n",
    "                # Global replace-one sensitivity for each score: Δ = 2C / n\n",
    "                Delta = 2.0 * xi / n\n",
    "                s = int(np.ceil(1.2 * s_star))\n",
    "                dx_peel_1 = dp_top_s_laplace_peeling(g, s-1, eps_s[0], Delta, rng=rgt)\n",
    "                dx_peel_2 = dp_top_s_laplace_peeling(g, s-1, eps_s[1], Delta, rng=rgt)\n",
    "        \n",
    "                #----------- initialization -----------\n",
    "                support_org_1 = np.asarray(list(dx_peel_1), dtype=int)\n",
    "                support_org_2 = np.asarray(list(dx_peel_2), dtype=int)\n",
    "                X_low_1 = X[:,support_org_1]\n",
    "                X_low_2 = X[:,support_org_2]\n",
    "                epsilon_tau =  eps_init/4  # privacy budget for DP standard deviation estimation: 1/4\n",
    "                epsilon_ridge =  3*eps_init/4 # privacy budget for DP huber+ridge estimation: 3/4\n",
    "                tau_init_1 =   St_DP(Y, epsilon = epsilon_tau[0]) \n",
    "                tau_init_2 =   St_DP(Y, epsilon = epsilon_tau[1])   \n",
    "                beta_0DP_1 =  huber_ridge_priv(X_low_1, Y, tau=tau_init_1, epsilon= epsilon_ridge[0], delta= delta_init) \n",
    "                beta_0DP_2 =  huber_ridge_priv(X_low_2, Y, tau=tau_init_2, epsilon= epsilon_ridge[1], delta= delta_init)\n",
    "                beta0DP_1 = np.zeros(p)\n",
    "                support_selected_1 = np.insert(support_org_1 + 1, 0, 0).astype(int) \n",
    "                beta0DP_1[support_selected_1] = beta_0DP_1 \n",
    "                beta0DP_2 = np.zeros(p)\n",
    "                support_selected_2 = np.insert(support_org_2 + 1, 0, 0).astype(int) \n",
    "                beta0DP_2[support_selected_2] = beta_0DP_2 \n",
    "                \n",
    "                #----------- estimation -----------\n",
    "                tau_priv_1 = .04 * tau_init_1 * (n*epsilon[0]/(s*np.log(p)+np.log(n)))**0.5 # robustification parameter for  DP    \n",
    "                tau_priv_2 = .04 * tau_init_2 * (n*epsilon[1]/(s*np.log(p)+np.log(n)))**0.5 \n",
    "                lr_priv =  0.01  \n",
    "                B_priv = 0.5*(np.log(p) + np.log(n))**0.5\n",
    "                T_priv = int(np.ceil(2*np.log(n))) # number of iterations\n",
    "                if T_priv*np.log(T_priv/delta_main) < 2.5*np.log(2/delta_main)*np.log((2*T_priv)/delta_main):\n",
    "                    epsilon_scale_priv = eps_main/T_priv\n",
    "                    delta_scale_priv = delta_main/T_priv\n",
    "                else: \n",
    "                    epsilon_scale_priv = eps_main/np.sqrt(2.5*T_priv*np.log(2/delta_main))\n",
    "                    delta_scale_priv = delta_main/ (2*T_priv)\n",
    "                model_est = Huber(X , Y ,intercept=True)\n",
    "                out_priv_1 = model_est.noisygd_highdim( s=s, lr=lr_priv, T=T_priv,  tau=tau_priv_1 , beta0=beta0DP_1,  B_high=B_priv,  epsilon_scale =epsilon_scale_priv[0],  delta_scale=delta_scale_priv )    \n",
    "                priv_rela_l2_1  = np.log((np.sum((out_priv_1['beta']  - beta )**2 ))**0.5  / beta_norm )\n",
    "                priv_rela_l2_comp = np.log((np.sum((out_priv_1['beta'][1:]  - beta_slope )**2 ))**0.5  / beta_slope_norm ) # epsilon = 0.5 for comparison with DP-ls\n",
    "                out_priv_2 = model_est.noisygd_highdim( s=s, lr=lr_priv, T=T_priv,  tau=tau_priv_2 , beta0=beta0DP_2,  B_high=B_priv,  epsilon_scale =epsilon_scale_priv[1],  delta_scale=delta_scale_priv )    \n",
    "                priv_rela_l2_2  = np.log((np.sum((out_priv_2['beta']  - beta )**2 ))**0.5  / beta_norm )\n",
    "                    \n",
    "                \n",
    "                ############################################### \n",
    "                #----------------  Non-private  --------------- \n",
    "                # ###############################################  \n",
    "                tau0 = np.sqrt(np.mean(Y**2)-(np.mean(Y)**2))\n",
    "                tau_np_high = .1 *tau0  * (n/(s*np.log(p)+np.log(n)))**0.5 # robustification parameter for noiseless Gaussian DP \n",
    "                lr_np =  0.2  \n",
    "                T_np = int(np.ceil(2*np.log(n))) # number of iterations \n",
    "                model_est = Huber(X , Y ,intercept=True)\n",
    "                out_np = model_est.gd_highdim(s=s, lr=lr_np, T=T_np,  tau=tau_np_high, beta0=np.array([]),  standardize= False) \n",
    "                rela_l2  =  np.log((np.sum((out_np['beta']   - beta  )**2))**0.5  / beta_norm)\n",
    "                rela_l2_comp = np.log((np.sum((out_np['beta'][1:]  - beta_slope )**2 ))**0.5  / beta_slope_norm ) # for comparison with DP-ls\n",
    "\n",
    "                \n",
    "                re_all = np.array([ priv_rela_l2_1,priv_rela_l2_2,rela_l2, priv_rela_l2_comp,rela_l2_comp])\n",
    "                results.append(re_all)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7a0c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e72d0f52f184082a042e1aadaf139f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test  \n",
    "cuda_cores = 20\n",
    "M = 300\n",
    "re_high_priv_est = np.array(Parallel(n_jobs=cuda_cores)(delayed(main_priv_est_parallel)(m ) for m in tqdm(range(M))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and reload\n",
    "np.save(\"re_high.npy\", re_high_priv_est)\n",
    "#re_high_priv_est = np.load(\"re_high.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e24db8f",
   "metadata": {},
   "source": [
    "### Differnt privacy levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11136f41",
   "metadata": {},
   "source": [
    "#### Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dca5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_re_eps(re_eps_p5000, n_set): \n",
    "    arr = np.asarray(re_eps_p5000)\n",
    "    n_set = np.asarray(n_set)\n",
    "\n",
    "    M, combos, n_methods = arr.shape\n",
    "    assert combos == 6, \"Second dimension of re_eps_p5000 must be 6 (2 noise types × 3 n's).\"\n",
    "    assert n_methods == 3, \"Last dimension must be 3 (eps=0.5, eps=0.9, Non-private).\"\n",
    "    assert len(n_set) == 3, \"This function currently assumes 3 sample sizes.\"\n",
    "\n",
    "    # Reshape to (M, 2 noise types, 3 sample sizes, 3 methods)\n",
    "    arr4 = arr.reshape(M, 2, 3, 3)\n",
    "\n",
    "    # Colors and labels for the 3 methods\n",
    "    method_colors = {\n",
    "        0: 'orange',      # DP, epsilon = 0.5\n",
    "        1: 'red',         # DP, epsilon = 0.9\n",
    "        2: 'deepskyblue'  # Non-private\n",
    "    }\n",
    "    method_labels = {\n",
    "        0: 'epsilon = 0.5',\n",
    "        1: 'epsilon = 0.9',\n",
    "        2: 'Non-private'\n",
    "    }\n",
    "\n",
    "    num_methods = 3\n",
    "    num_n = len(n_set)\n",
    "\n",
    "    # For each sample size n, we place 3 method boxplots side by side,\n",
    "    # and leave some gap between different n-groups.\n",
    "    group_width = num_methods + 1.0\n",
    "    group_centers = np.arange(num_n) * group_width\n",
    "\n",
    "    noise_names = [r'$N(0,1)\\ \\mathrm{noise}$', r'$t_{2.25}\\ \\mathrm{noise}$']\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4), dpi=300)\n",
    "    axs = np.atleast_1d(axs)\n",
    "\n",
    "    for noise_idx in range(2):\n",
    "        ax = axs[noise_idx]\n",
    "\n",
    "        box_data = []\n",
    "        box_positions = []\n",
    "\n",
    "        # Loop over sample sizes and methods\n",
    "        for k in range(num_n):          # index of n\n",
    "            for m_idx in range(num_methods):  # index of method\n",
    "                # Values across M replications\n",
    "                vals = arr4[:, noise_idx, k, m_idx]  # shape: (M,)\n",
    "                box_data.append(vals)\n",
    "\n",
    "                # Horizontal position of this box\n",
    "                pos = group_centers[k] + m_idx\n",
    "                box_positions.append(pos)\n",
    "\n",
    "        # Draw boxplots\n",
    "        bp = ax.boxplot(\n",
    "            box_data,\n",
    "            positions=box_positions,\n",
    "            widths=0.6,\n",
    "            patch_artist=True,\n",
    "            showfliers=False  # hide outliers to avoid extreme compression of y-axis\n",
    "        )\n",
    "\n",
    "        # Color the boxes according to method\n",
    "        for i, patch in enumerate(bp['boxes']):\n",
    "            m_idx = i % num_methods\n",
    "            patch.set_facecolor(method_colors[m_idx])\n",
    "            patch.set_edgecolor('black')\n",
    "            patch.set_alpha(0.7)\n",
    "\n",
    "        # Style the medians\n",
    "        for median in bp['medians']:\n",
    "            median.set_color('black')\n",
    "            median.set_linewidth(1.2)\n",
    "\n",
    "        # Set x-ticks at the center of each group (corresponding to each n)\n",
    "        ax.set_xticks(group_centers + (num_methods - 1) / 2.0)\n",
    "        xtick_labels = [rf'$n={int(v)}$' for v in n_set]\n",
    "        ax.set_xticklabels(xtick_labels, fontsize=10)\n",
    "        ax.set_xlabel('Sample size', fontsize=11, fontweight='bold')\n",
    "\n",
    "        # Draw vertical dashed lines between groups of different n\n",
    "        for k in range(num_n - 1):\n",
    "            last_k = group_centers[k] + (num_methods - 1)\n",
    "            first_k1 = group_centers[k+1]\n",
    "            x_sep = 0.5 * (last_k + first_k1)\n",
    "            ax.axvline(\n",
    "                x=x_sep,\n",
    "                color='grey',\n",
    "                linestyle='--',\n",
    "                linewidth=1,\n",
    "                alpha=0.6,\n",
    "                zorder=0\n",
    "            )\n",
    "\n",
    "        # y-axis label: log relative L2 error\n",
    "        ax.set_ylabel(\n",
    "            r'${\\rm \\mathbf{Log~relative~}}~ \\boldsymbol{\\ell}_2$-error',\n",
    "            fontsize=11,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "        ax.set_title(noise_names[noise_idx], fontsize=12, fontweight='bold')\n",
    "\n",
    "        # Axis styling\n",
    "        ax.set_facecolor('white')\n",
    "        ax.spines['left'].set_visible(True)\n",
    "        ax.spines['bottom'].set_visible(True)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        ax.spines['left'].set_linewidth(1.5)\n",
    "        ax.spines['bottom'].set_linewidth(1.5)\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.tick_params(axis='both', which='major', labelsize=9)\n",
    "\n",
    "    # Shared legend for the three methods\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], color=method_colors[i], lw=3)\n",
    "        for i in range(num_methods)\n",
    "    ]\n",
    "    legend_labels = [method_labels[i] for i in range(num_methods)]\n",
    "    fig.legend(\n",
    "        legend_handles,\n",
    "        legend_labels,\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(0.95, 0.5),\n",
    "        frameon=True,\n",
    "        prop={'size': 10}\n",
    "    )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_eps_p5000 = re_high_priv_est[:, 0:6, :3] # different epsilon for p = 5000\n",
    "re_eps_p10000 = re_high_priv_est[:, 6:12, :3] # different epsilon for p = 10000\n",
    "n_set = [5000, 10000, 15000]\n",
    "fig, axs = plot_re_eps(re_eps_p10000, n_set)\n",
    "#fig.savefig(\"Est_high_p5000.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87936327",
   "metadata": {},
   "source": [
    "### Comparison results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_comp_p5000 = re_high_priv_est[:, 0:6, 3:] # comparison results with DP-LS for p = 5000\n",
    "re_comp_p10000 = re_high_priv_est[:, 6:12, 3:] # comparison results with DP-LS for p = 10000\n",
    "re_comp_p5000_array = np.round(np.mean(re_comp_p5000, axis=0),3)\n",
    "re_comp_p10000_array = np.round(np.mean(re_comp_p10000, axis=0),3)\n",
    "re_comp_p5000_array\n",
    "#re_comp_p10000_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcea413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_high_p5000 = pd.DataFrame(re_comp_p5000_array) \n",
    "df_high_p5000.to_csv(\"results_highdim_comp_p5000.csv\", index=False)\n",
    "df_high_p10000 = pd.DataFrame(re_comp_p10000_array) \n",
    "df_high_p10000.to_csv(\"results_highdim_comp_p10000.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
